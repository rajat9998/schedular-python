"""initial setup

Revision ID: c28f05ab88a2
Revises: 
Create Date: 2025-09-22 02:56:48.412338

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = 'c28f05ab88a2'
down_revision = None
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('jobs',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('name', sa.String(length=255), nullable=False),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('job_type', sa.Enum('EMAIL_NOTIFICATION', 'DATA_PROCESSING', 'REPORT_GENERATION', 'CLEANUP_TASK', 'BACKUP_TASK', 'CUSTOM', name='jobtype'), nullable=False),
    sa.Column('cron_expression', sa.String(length=100), nullable=True),
    sa.Column('interval_seconds', sa.Integer(), nullable=True),
    sa.Column('next_run_time', sa.DateTime(timezone=True), nullable=True),
    sa.Column('last_run_time', sa.DateTime(timezone=True), nullable=True),
    sa.Column('job_data', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('max_retries', sa.Integer(), nullable=True),
    sa.Column('retry_count', sa.Integer(), nullable=True),
    sa.Column('timeout_seconds', sa.Integer(), nullable=True),
    sa.Column('status', sa.Enum('PENDING', 'RUNNING', 'COMPLETED', 'FAILED', 'PAUSED', 'CANCELLED', name='jobstatus'), nullable=False),
    sa.Column('is_active', sa.Boolean(), nullable=True),
    sa.Column('priority', sa.Integer(), nullable=True),
    sa.Column('total_runs', sa.Integer(), nullable=True),
    sa.Column('successful_runs', sa.Integer(), nullable=True),
    sa.Column('failed_runs', sa.Integer(), nullable=True),
    sa.Column('average_runtime', sa.Float(), nullable=True),
    sa.Column('created_by', sa.String(length=255), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('jobs', schema=None) as batch_op:
        batch_op.create_index('idx_job_created_by_status', ['created_by', 'status'], unique=False)
        batch_op.create_index('idx_job_next_run_active', ['next_run_time', 'is_active'], unique=False)
        batch_op.create_index('idx_job_priority_next_run', ['priority', 'next_run_time'], unique=False)
        batch_op.create_index('idx_job_status_type', ['status', 'job_type'], unique=False)
        batch_op.create_index(batch_op.f('ix_jobs_created_by'), ['created_by'], unique=False)
        batch_op.create_index(batch_op.f('ix_jobs_id'), ['id'], unique=False)
        batch_op.create_index(batch_op.f('ix_jobs_is_active'), ['is_active'], unique=False)
        batch_op.create_index(batch_op.f('ix_jobs_name'), ['name'], unique=False)
        batch_op.create_index(batch_op.f('ix_jobs_next_run_time'), ['next_run_time'], unique=False)
        batch_op.create_index(batch_op.f('ix_jobs_priority'), ['priority'], unique=False)

    op.create_table('job_executions',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('job_id', sa.UUID(), nullable=False),
    sa.Column('started_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('completed_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('duration', sa.Float(), nullable=True),
    sa.Column('status', sa.Enum('PENDING', 'RUNNING', 'COMPLETED', 'FAILED', 'PAUSED', 'CANCELLED', name='jobstatus'), nullable=False),
    sa.Column('result', sa.Text(), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('stack_trace', sa.Text(), nullable=True),
    sa.Column('worker_node', sa.String(length=255), nullable=True),
    sa.Column('execution_context', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.ForeignKeyConstraint(['job_id'], ['jobs.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('job_executions', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_job_executions_job_id'), ['job_id'], unique=False)

    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('job_executions', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_job_executions_job_id'))

    op.drop_table('job_executions')
    with op.batch_alter_table('jobs', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_jobs_priority'))
        batch_op.drop_index(batch_op.f('ix_jobs_next_run_time'))
        batch_op.drop_index(batch_op.f('ix_jobs_name'))
        batch_op.drop_index(batch_op.f('ix_jobs_is_active'))
        batch_op.drop_index(batch_op.f('ix_jobs_id'))
        batch_op.drop_index(batch_op.f('ix_jobs_created_by'))
        batch_op.drop_index('idx_job_status_type')
        batch_op.drop_index('idx_job_priority_next_run')
        batch_op.drop_index('idx_job_next_run_active')
        batch_op.drop_index('idx_job_created_by_status')

    op.drop_table('jobs')
    # ### end Alembic commands ###
